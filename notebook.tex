
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{housing}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}127}]:} \PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k}{import} \PY{n}{print\PYZus{}function}
          
          \PY{k+kn}{import} \PY{n+nn}{math}
          
          \PY{k+kn}{from} \PY{n+nn}{IPython} \PY{k}{import} \PY{n}{display}
          \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{cm}
          \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{gridspec}
          \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{as} \PY{n+nn}{metrics}
          \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
          \PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{python}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{Dataset}
          
          \PY{n}{tf}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{set\PYZus{}verbosity}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{ERROR}\PY{p}{)}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:.1f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}
          
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data/train.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{,}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{reindex}\PY{p}{(}
              \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{permutation}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{index}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} housing\PYZus{}dataframe.reset\PYZus{}index(drop=True)}
          \PY{c+c1}{\PYZsh{} housing\PYZus{}dataframe = housing\PYZus{}dataframe.reindex(}
          \PY{c+c1}{\PYZsh{}     np.random.permutation(housing\PYZus{}dataframe.index))}
          
          \PY{c+c1}{\PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}TotRmsAbvGrd\PYZdq{}].apply(lambda x: min(x, 13))}
          \PY{c+c1}{\PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}TotRmsAbvGrd\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}OverallQual\PYZdq{}].apply(lambda x: min(x, 9.5))}
          \PY{c+c1}{\PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}OverallQual\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}GrLivArea\PYZdq{}].apply(lambda x: max(x, 3500))}
          \PY{c+c1}{\PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}GrLivArea\PYZdq{}] = clipped\PYZus{}feature}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}128}]:} \PY{k}{def} \PY{n+nf}{preprocess\PYZus{}features}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Prepares input features from California housing data set.}
          
          \PY{l+s+sd}{  Args:}
          \PY{l+s+sd}{    california\PYZus{}housing\PYZus{}dataframe: A Pandas DataFrame expected to contain data}
          \PY{l+s+sd}{      from the California housing data set.}
          \PY{l+s+sd}{  Returns:}
          \PY{l+s+sd}{    A DataFrame that contains the features to be used for the model, including}
          \PY{l+s+sd}{    synthetic features.}
          \PY{l+s+sd}{  \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{selected\PYZus{}features} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}
              \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{OverallQual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotalBsmtSF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{1stFlrSF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GrLivArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{FullBath}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotRmsAbvGrd}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fireplaces}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageYrBlt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageCars}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}
            \PY{n}{processed\PYZus{}features} \PY{o}{=} \PY{n}{selected\PYZus{}features}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
          
          
          \PY{c+c1}{\PYZsh{}   \PYZsh{} \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}clipping\PYZus{}features}
          \PY{c+c1}{\PYZsh{}   clipped\PYZus{}feature = processed\PYZus{}features[\PYZdq{}TotRmsAbvGrd\PYZdq{}].apply(lambda x: min(x, 13))}
          \PY{c+c1}{\PYZsh{}   processed\PYZus{}features[\PYZdq{}TotRmsAbvGrd\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{}   clipped\PYZus{}feature = processed\PYZus{}features[\PYZdq{}OverallQual\PYZdq{}].apply(lambda x: min(x, 9))}
          \PY{c+c1}{\PYZsh{}   processed\PYZus{}features[\PYZdq{}OverallQual\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{}   clipped\PYZus{}feature = processed\PYZus{}features[\PYZdq{}GrLivArea\PYZdq{}].apply(lambda x: min(x, 3500))}
          \PY{c+c1}{\PYZsh{}   processed\PYZus{}features[\PYZdq{}GrLivArea\PYZdq{}] = clipped\PYZus{}feature}
          
          
            \PY{c+c1}{\PYZsh{} Create a synthetic feature.}
          \PY{c+c1}{\PYZsh{}   processed\PYZus{}features[\PYZdq{}rooms\PYZus{}per\PYZus{}person\PYZdq{}] = (}
          \PY{c+c1}{\PYZsh{}     california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}total\PYZus{}rooms\PYZdq{}] /}
          \PY{c+c1}{\PYZsh{}     california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}population\PYZdq{}])}
            \PY{k}{return} \PY{n}{processed\PYZus{}features}
          
          \PY{k}{def} \PY{n+nf}{preprocess\PYZus{}targets}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Prepares target features (i.e., labels) from California housing data set.}
          
          \PY{l+s+sd}{  Args:}
          \PY{l+s+sd}{    california\PYZus{}housing\PYZus{}dataframe: A Pandas DataFrame expected to contain data}
          \PY{l+s+sd}{      from the California housing data set.}
          \PY{l+s+sd}{  Returns:}
          \PY{l+s+sd}{    A DataFrame that contains the target feature.}
          \PY{l+s+sd}{  \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{output\PYZus{}targets} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Scale the target to be in units of thousands of dollars.}
            \PY{n}{output\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mf}{1000.0}
            \PY{k}{return} \PY{n}{output\PYZus{}targets}
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}128}]:}         Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \textbackslash{}
          690    691         120       RM          nan     4426   Pave   NaN      Reg   
          937    938          60       RL         75.0     9675   Pave   NaN      Reg   
          1368  1369         120       RM          nan     4435   Pave   NaN      Reg   
          864    865          20       FV         72.0     8640   Pave   NaN      Reg   
          415    416          20       RL         73.0     8899   Pave   NaN      IR1   
          {\ldots}    {\ldots}         {\ldots}      {\ldots}          {\ldots}      {\ldots}    {\ldots}   {\ldots}      {\ldots}   
          1203  1204          20       RL         75.0     9750   Pave   NaN      Reg   
          805    806          20       RL         91.0    12274   Pave   NaN      IR1   
          97      98          20       RL         73.0    10921   Pave   NaN      Reg   
          670    671          60       RL         64.0     8633   Pave   NaN      Reg   
          700    701          20       RL         85.0    14331   Pave   NaN      Reg   
          
               LandContour Utilities    {\ldots}     PoolArea PoolQC Fence MiscFeature  \textbackslash{}
          690          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          937          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          1368         Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          864          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          415          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          {\ldots}          {\ldots}       {\ldots}    {\ldots}          {\ldots}    {\ldots}   {\ldots}         {\ldots}   
          1203         Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          805          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          97           HLS    AllPub    {\ldots}            0    NaN   NaN         NaN   
          670          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          700          Lvl    AllPub    {\ldots}            0    NaN   NaN         NaN   
          
               MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  
          690        0      5   2008        WD         Normal     141000  
          937        0      2   2009        WD         Normal     253000  
          1368       0      6   2009        WD         Normal     144000  
          864        0      5   2008       New        Partial     250580  
          415        0      8   2007       New        Partial     181134  
          {\ldots}      {\ldots}    {\ldots}    {\ldots}       {\ldots}            {\ldots}        {\ldots}  
          1203       0     10   2009        WD         Normal     213000  
          805        0      7   2008       New        Partial     227680  
          97         0      5   2007        WD         Normal      94750  
          670        0      2   2009        WD         Normal     173500  
          700        0      5   2006        WD         Normal     312500  
          
          [1460 rows x 81 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}129}]:} \PY{c+c1}{\PYZsh{} Choose the first 12000 (out of 17000) examples for training.}
          \PY{n}{training\PYZus{}examples} \PY{o}{=} \PY{n}{preprocess\PYZus{}features}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{)}
          \PY{n}{training\PYZus{}targets} \PY{o}{=} \PY{n}{preprocess\PYZus{}targets}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Choose the last 5000 (out of 17000) examples for validation.}
          \PY{n}{validation\PYZus{}examples} \PY{o}{=} \PY{n}{preprocess\PYZus{}features}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{460}\PY{p}{)}\PY{p}{)}
          \PY{n}{validation\PYZus{}targets} \PY{o}{=} \PY{n}{preprocess\PYZus{}targets}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{460}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} display.display(california\PYZus{}housing\PYZus{}dataframe.describe())}
          
          \PY{c+c1}{\PYZsh{} Double\PYZhy{}check that we\PYZsq{}ve done the right thing.}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training examples summary:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{display}\PY{o}{.}\PY{n}{display}\PY{p}{(}\PY{n}{training\PYZus{}examples}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation examples summary:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{display}\PY{o}{.}\PY{n}{display}\PY{p}{(}\PY{n}{validation\PYZus{}examples}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training targets summary:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{display}\PY{o}{.}\PY{n}{display}\PY{p}{(}\PY{n}{training\PYZus{}targets}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation targets summary:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{display}\PY{o}{.}\PY{n}{display}\PY{p}{(}\PY{n}{validation\PYZus{}targets}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Training examples summary:

    \end{Verbatim}

    
    \begin{verbatim}
       OverallQual  TotalBsmtSF  1stFlrSF  GrLivArea  FullBath  TotRmsAbvGrd  \
count       1000.0       1000.0    1000.0     1000.0    1000.0        1000.0   
mean           6.1       1056.7    1160.5     1503.5       1.6           6.5   
std            1.4        434.9     383.8      512.5       0.6           1.6   
min            1.0          0.0     334.0      334.0       0.0           2.0   
25%            5.0        798.0     878.2     1134.2       1.0           5.0   
50%            6.0        997.0    1088.0     1452.5       2.0           6.0   
75%            7.0       1276.2    1383.0     1750.5       2.0           7.0   
max           10.0       6110.0    4692.0     5642.0       3.0          12.0   

       Fireplaces  GarageYrBlt  GarageCars  GarageArea  
count      1000.0        947.0      1000.0      1000.0  
mean          0.6       1978.6         1.8       472.6  
std           0.6         24.5         0.7       212.0  
min           0.0       1900.0         0.0         0.0  
25%           0.0       1961.0         1.0       336.0  
50%           1.0       1980.0         2.0       479.0  
75%           1.0       2002.0         2.0       576.0  
max           3.0       2010.0         4.0      1418.0  
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
Validation examples summary:

    \end{Verbatim}

    
    \begin{verbatim}
       OverallQual  TotalBsmtSF  1stFlrSF  GrLivArea  FullBath  TotRmsAbvGrd  \
count        460.0        460.0     460.0      460.0     460.0         460.0   
mean           6.2       1059.0    1167.2     1541.5       1.6           6.6   
std            1.4        447.4     392.9      552.4       0.5           1.7   
min            3.0          0.0     483.0      520.0       1.0           3.0   
25%            5.0        788.8     886.8     1124.8       1.0           5.0   
50%            6.0        970.0    1086.0     1482.0       2.0           6.0   
75%            7.0       1316.5    1417.5     1830.5       2.0           7.0   
max           10.0       3206.0    3138.0     4676.0       3.0          14.0   

       Fireplaces  GarageYrBlt  GarageCars  GarageArea  
count       460.0        432.0       460.0       460.0  
mean          0.7       1978.3         1.8       473.9  
std           0.7         25.0         0.8       217.9  
min           0.0       1908.0         0.0         0.0  
25%           0.0       1961.0         1.0       312.0  
50%           1.0       1980.0         2.0       480.0  
75%           1.0       2002.0         2.0       579.2  
max           3.0       2009.0         4.0      1166.0  
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
Training targets summary:

    \end{Verbatim}

    
    \begin{verbatim}
       SalePrice
count     1000.0
mean       179.1
std         77.0
min         34.9
25%        130.0
50%        162.7
75%        207.5
max        745.0
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
Validation targets summary:

    \end{Verbatim}

    
    \begin{verbatim}
       SalePrice
count      460.0
mean       184.9
std         84.5
min         52.0
25%        129.0
50%        165.0
75%        225.7
max        755.0
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{c+c1}{\PYZsh{} \PYZsh{}find good feratures based on sale price}
         \PY{c+c1}{\PYZsh{} correlation\PYZus{}dataframe = california\PYZus{}housing\PYZus{}dataframe.copy()}
         \PY{c+c1}{\PYZsh{} correlation\PYZus{}dataframe[\PYZdq{}target\PYZdq{}] = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}SalePrice\PYZdq{}]}
         
         \PY{c+c1}{\PYZsh{} \PYZsh{} display.display(training\PYZus{}targets.describe())}
         
         \PY{c+c1}{\PYZsh{} correlation\PYZus{}dataframe.corr()}
         \PY{c+c1}{\PYZsh{} new = pd.DataFrame()}
         \PY{c+c1}{\PYZsh{} new[\PYZsq{}target\PYZsq{}] = correlation\PYZus{}dataframe.corr()[\PYZsq{}target\PYZsq{}]}
         \PY{c+c1}{\PYZsh{} new.to\PYZus{}csv(\PYZsq{}corr.csv\PYZsq{})}
         \PY{c+c1}{\PYZsh{} \PYZsh{} correlation\PYZus{}dataframe[\PYZdq{}OpenPorchSF\PYZdq{}].corr()}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{n}{correlation\PYZus{}dataframe} \PY{o}{=} \PY{n}{training\PYZus{}examples}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
          \PY{n}{correlation\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{target}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{training\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} display.display(training\PYZus{}targets.describe())}
          
          \PY{n}{correlation\PYZus{}dataframe}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}130}]:}              OverallQual  TotalBsmtSF  1stFlrSF  GrLivArea  FullBath  \textbackslash{}
          OverallQual          1.0          0.5       0.5        0.6       0.5   
          TotalBsmtSF          0.5          1.0       0.8        0.5       0.3   
          1stFlrSF             0.5          0.8       1.0        0.6       0.3   
          GrLivArea            0.6          0.5       0.6        1.0       0.6   
          FullBath             0.5          0.3       0.3        0.6       1.0   
          {\ldots}                  {\ldots}          {\ldots}       {\ldots}        {\ldots}       {\ldots}   
          Fireplaces           0.4          0.3       0.4        0.5       0.2   
          GarageYrBlt          0.6          0.3       0.2        0.2       0.5   
          GarageCars           0.6          0.4       0.4        0.5       0.4   
          GarageArea           0.6          0.5       0.5        0.5       0.4   
          target               0.8          0.6       0.6        0.7       0.6   
          
                       TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  GarageArea  \textbackslash{}
          OverallQual           0.4         0.4          0.6         0.6         0.6   
          TotalBsmtSF           0.3         0.3          0.3         0.4         0.5   
          1stFlrSF              0.4         0.4          0.2         0.4         0.5   
          GrLivArea             0.8         0.5          0.2         0.5         0.5   
          FullBath              0.6         0.2          0.5         0.4         0.4   
          {\ldots}                   {\ldots}         {\ldots}          {\ldots}         {\ldots}         {\ldots}   
          Fireplaces            0.3         1.0          0.0         0.3         0.3   
          GarageYrBlt           0.1         0.0          1.0         0.6         0.6   
          GarageCars            0.3         0.3          0.6         1.0         0.9   
          GarageArea            0.3         0.3          0.6         0.9         1.0   
          target                0.5         0.5          0.5         0.6         0.6   
          
                       target  
          OverallQual     0.8  
          TotalBsmtSF     0.6  
          1stFlrSF        0.6  
          GrLivArea       0.7  
          FullBath        0.6  
          {\ldots}             {\ldots}  
          Fireplaces      0.5  
          GarageYrBlt     0.5  
          GarageCars      0.6  
          GarageArea      0.6  
          target          1.0  
          
          [11 rows x 11 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{k}{def} \PY{n+nf}{my\PYZus{}input\PYZus{}fn}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Trains a linear regression model.}
          \PY{l+s+sd}{  }
          \PY{l+s+sd}{    Args:}
          \PY{l+s+sd}{      features: pandas DataFrame of features}
          \PY{l+s+sd}{      targets: pandas DataFrame of targets}
          \PY{l+s+sd}{      batch\PYZus{}size: Size of batches to be passed to the model}
          \PY{l+s+sd}{      shuffle: True or False. Whether to shuffle the data.}
          \PY{l+s+sd}{      num\PYZus{}epochs: Number of epochs for which data should be repeated. None = repeat indefinitely}
          \PY{l+s+sd}{    Returns:}
          \PY{l+s+sd}{      Tuple of (features, labels) for next data batch}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              
              \PY{c+c1}{\PYZsh{} Convert pandas data into a dict of np arrays.}
              \PY{n}{features} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{key}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{value}\PY{p}{)} \PY{k}{for} \PY{n}{key}\PY{p}{,}\PY{n}{value} \PY{o+ow}{in} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{features}\PY{p}{)}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}                                           
              
              \PY{c+c1}{\PYZsh{} Construct a dataset, and configure batching/repeating.}
              \PY{n}{ds} \PY{o}{=} \PY{n}{Dataset}\PY{o}{.}\PY{n}{from\PYZus{}tensor\PYZus{}slices}\PY{p}{(}\PY{p}{(}\PY{n}{features}\PY{p}{,}\PY{n}{targets}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} warning: 2GB limit}
              \PY{n}{ds} \PY{o}{=} \PY{n}{ds}\PY{o}{.}\PY{n}{batch}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{o}{.}\PY{n}{repeat}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Shuffle the data, if specified.}
              \PY{k}{if} \PY{n}{shuffle}\PY{p}{:}
                \PY{n}{ds} \PY{o}{=} \PY{n}{ds}\PY{o}{.}\PY{n}{shuffle}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{} Return the next batch of data.}
              \PY{n}{features}\PY{p}{,} \PY{n}{labels} \PY{o}{=} \PY{n}{ds}\PY{o}{.}\PY{n}{make\PYZus{}one\PYZus{}shot\PYZus{}iterator}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}next}\PY{p}{(}\PY{p}{)}
              \PY{k}{return} \PY{n}{features}\PY{p}{,} \PY{n}{labels}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}132}]:} \PY{k}{def} \PY{n+nf}{construct\PYZus{}feature\PYZus{}columns}\PY{p}{(}\PY{n}{input\PYZus{}features}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Construct the TensorFlow Feature Columns.}
          
          \PY{l+s+sd}{  Args:}
          \PY{l+s+sd}{    input\PYZus{}features: The names of the numerical input features to use.}
          \PY{l+s+sd}{  Returns:}
          \PY{l+s+sd}{    A set of feature columns}
          \PY{l+s+sd}{  \PYZdq{}\PYZdq{}\PYZdq{}} 
            \PY{k}{return} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n}{tf}\PY{o}{.}\PY{n}{feature\PYZus{}column}\PY{o}{.}\PY{n}{numeric\PYZus{}column}\PY{p}{(}\PY{n}{my\PYZus{}feature}\PY{p}{)}
                        \PY{k}{for} \PY{n}{my\PYZus{}feature} \PY{o+ow}{in} \PY{n}{input\PYZus{}features}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{k}{def} \PY{n+nf}{train\PYZus{}nn\PYZus{}regression\PYZus{}model}\PY{p}{(}
              \PY{n}{my\PYZus{}optimizer}\PY{p}{,}
              \PY{n}{steps}\PY{p}{,}
              \PY{n}{batch\PYZus{}size}\PY{p}{,}
              \PY{n}{hidden\PYZus{}units}\PY{p}{,}
              \PY{n}{training\PYZus{}examples}\PY{p}{,}
              \PY{n}{training\PYZus{}targets}\PY{p}{,}
              \PY{n}{validation\PYZus{}examples}\PY{p}{,}
              \PY{n}{validation\PYZus{}targets}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Trains a neural network regression model.}
          \PY{l+s+sd}{  }
          \PY{l+s+sd}{  In addition to training, this function also prints training progress information,}
          \PY{l+s+sd}{  as well as a plot of the training and validation loss over time.}
          \PY{l+s+sd}{  }
          \PY{l+s+sd}{  Args:}
          \PY{l+s+sd}{    my\PYZus{}optimizer: An instance of `tf.train.Optimizer`, the optimizer to use.}
          \PY{l+s+sd}{    steps: A non\PYZhy{}zero `int`, the total number of training steps. A training step}
          \PY{l+s+sd}{      consists of a forward and backward pass using a single batch.}
          \PY{l+s+sd}{    batch\PYZus{}size: A non\PYZhy{}zero `int`, the batch size.}
          \PY{l+s+sd}{    hidden\PYZus{}units: A `list` of int values, specifying the number of neurons in each layer.}
          \PY{l+s+sd}{    training\PYZus{}examples: A `DataFrame` containing one or more columns from}
          \PY{l+s+sd}{      `california\PYZus{}housing\PYZus{}dataframe` to use as input features for training.}
          \PY{l+s+sd}{    training\PYZus{}targets: A `DataFrame` containing exactly one column from}
          \PY{l+s+sd}{      `california\PYZus{}housing\PYZus{}dataframe` to use as target for training.}
          \PY{l+s+sd}{    validation\PYZus{}examples: A `DataFrame` containing one or more columns from}
          \PY{l+s+sd}{      `california\PYZus{}housing\PYZus{}dataframe` to use as input features for validation.}
          \PY{l+s+sd}{    validation\PYZus{}targets: A `DataFrame` containing exactly one column from}
          \PY{l+s+sd}{      `california\PYZus{}housing\PYZus{}dataframe` to use as target for validation.}
          \PY{l+s+sd}{      }
          \PY{l+s+sd}{  Returns:}
          \PY{l+s+sd}{    A tuple `(estimator, training\PYZus{}losses, validation\PYZus{}losses)`:}
          \PY{l+s+sd}{      estimator: the trained `DNNRegressor` object.}
          \PY{l+s+sd}{      training\PYZus{}losses: a `list` containing the training loss values taken during training.}
          \PY{l+s+sd}{      validation\PYZus{}losses: a `list` containing the validation loss values taken during training.}
          \PY{l+s+sd}{  \PYZdq{}\PYZdq{}\PYZdq{}}
          
            \PY{n}{periods} \PY{o}{=} \PY{l+m+mi}{10}
            \PY{n}{steps\PYZus{}per\PYZus{}period} \PY{o}{=} \PY{n}{steps} \PY{o}{/} \PY{n}{periods}
            
            \PY{c+c1}{\PYZsh{} Create a DNNRegressor object.}
            \PY{n}{my\PYZus{}optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{estimator}\PY{o}{.}\PY{n}{clip\PYZus{}gradients\PYZus{}by\PYZus{}norm}\PY{p}{(}\PY{n}{my\PYZus{}optimizer}\PY{p}{,} \PY{l+m+mf}{5.0}\PY{p}{)}
            \PY{n}{dnn\PYZus{}regressor} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{estimator}\PY{o}{.}\PY{n}{DNNRegressor}\PY{p}{(}
                \PY{n}{feature\PYZus{}columns}\PY{o}{=}\PY{n}{construct\PYZus{}feature\PYZus{}columns}\PY{p}{(}\PY{n}{training\PYZus{}examples}\PY{p}{)}\PY{p}{,}
                \PY{n}{hidden\PYZus{}units}\PY{o}{=}\PY{n}{hidden\PYZus{}units}\PY{p}{,}
                \PY{n}{optimizer}\PY{o}{=}\PY{n}{my\PYZus{}optimizer}
            \PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Create input functions.}
            \PY{n}{training\PYZus{}input\PYZus{}fn} \PY{o}{=} \PY{k}{lambda}\PY{p}{:} \PY{n}{my\PYZus{}input\PYZus{}fn}\PY{p}{(}\PY{n}{training\PYZus{}examples}\PY{p}{,} 
                                                    \PY{n}{training\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} 
                                                    \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{)}
            \PY{n}{predict\PYZus{}training\PYZus{}input\PYZus{}fn} \PY{o}{=} \PY{k}{lambda}\PY{p}{:} \PY{n}{my\PYZus{}input\PYZus{}fn}\PY{p}{(}\PY{n}{training\PYZus{}examples}\PY{p}{,} 
                                                            \PY{n}{training\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} 
                                                            \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} 
                                                            \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
            \PY{n}{predict\PYZus{}validation\PYZus{}input\PYZus{}fn} \PY{o}{=} \PY{k}{lambda}\PY{p}{:} \PY{n}{my\PYZus{}input\PYZus{}fn}\PY{p}{(}\PY{n}{validation\PYZus{}examples}\PY{p}{,} 
                                                              \PY{n}{validation\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} 
                                                              \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} 
                                                              \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
          
            \PY{c+c1}{\PYZsh{} Train the model, but do so inside a loop so that we can periodically assess}
            \PY{c+c1}{\PYZsh{} loss metrics.}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training model...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RMSE (on training data):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{training\PYZus{}rmse} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{n}{validation\PYZus{}rmse} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{period} \PY{o+ow}{in} \PY{n+nb}{range} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{periods}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} Train the model, starting from the prior state.}
              \PY{n}{dnn\PYZus{}regressor}\PY{o}{.}\PY{n}{train}\PY{p}{(}
                  \PY{n}{input\PYZus{}fn}\PY{o}{=}\PY{n}{training\PYZus{}input\PYZus{}fn}\PY{p}{,}
                  \PY{n}{steps}\PY{o}{=}\PY{n}{steps\PYZus{}per\PYZus{}period}
              \PY{p}{)}
              \PY{c+c1}{\PYZsh{} Take a break and compute predictions.}
              \PY{n}{training\PYZus{}predictions} \PY{o}{=} \PY{n}{dnn\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}fn}\PY{o}{=}\PY{n}{predict\PYZus{}training\PYZus{}input\PYZus{}fn}\PY{p}{)}
              \PY{n}{training\PYZus{}predictions} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{item}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{training\PYZus{}predictions}\PY{p}{]}\PY{p}{)}
              
              \PY{n}{validation\PYZus{}predictions} \PY{o}{=} \PY{n}{dnn\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}fn}\PY{o}{=}\PY{n}{predict\PYZus{}validation\PYZus{}input\PYZus{}fn}\PY{p}{)}
              \PY{n}{validation\PYZus{}predictions} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{item}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{validation\PYZus{}predictions}\PY{p}{]}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{} Compute training and validation loss.}
              \PY{n}{training\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}
                  \PY{n}{metrics}\PY{o}{.}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{training\PYZus{}predictions}\PY{p}{,} \PY{n}{training\PYZus{}targets}\PY{p}{)}\PY{p}{)}
              \PY{n}{validation\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}
                  \PY{n}{metrics}\PY{o}{.}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{validation\PYZus{}predictions}\PY{p}{,} \PY{n}{validation\PYZus{}targets}\PY{p}{)}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} Occasionally print the current loss.}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  period }\PY{l+s+si}{\PYZpc{}02d}\PY{l+s+s2}{ : }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{period}\PY{p}{,} \PY{n}{training\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} Add the loss metrics from this period to our list.}
              \PY{n}{training\PYZus{}rmse}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{training\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}
              \PY{n}{validation\PYZus{}rmse}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{validation\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model training finished.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
            \PY{c+c1}{\PYZsh{} Output a graph of loss metrics over periods.}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RMSE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Periods}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Root Mean Squared Error vs. Periods}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{training\PYZus{}rmse}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{validation\PYZus{}rmse}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{validation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
          
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Final RMSE (on training data):   }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{training\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Final RMSE (on validation data): }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{validation\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}
          
            \PY{k}{return} \PY{n}{dnn\PYZus{}regressor}\PY{p}{,} \PY{n}{training\PYZus{}rmse}\PY{p}{,} \PY{n}{validation\PYZus{}rmse}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}134}]:} \PY{k}{def} \PY{n+nf}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{:}
            \PY{n}{min\PYZus{}val} \PY{o}{=} \PY{n}{series}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}
            \PY{n}{max\PYZus{}val} \PY{o}{=} \PY{n}{series}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}
            \PY{n}{scale} \PY{o}{=} \PY{p}{(}\PY{n}{max\PYZus{}val} \PY{o}{\PYZhy{}} \PY{n}{min\PYZus{}val}\PY{p}{)} \PY{o}{/} \PY{l+m+mf}{2.0}
            \PY{k}{return} \PY{n}{series}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:}\PY{p}{(}\PY{p}{(}\PY{n}{x} \PY{o}{\PYZhy{}} \PY{n}{min\PYZus{}val}\PY{p}{)} \PY{o}{/} \PY{n}{scale}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mf}{1.0}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}137}]:} \PY{c+c1}{\PYZsh{} minimal\PYZus{}features = [}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}OverallQual\PYZdq{},}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}GrLivArea\PYZdq{},}
          \PY{c+c1}{\PYZsh{} \PYZsh{}      \PYZdq{}TotRmsAbvGrd\PYZdq{},}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}TotalBsmtSF\PYZdq{},}
          \PY{c+c1}{\PYZsh{} \PYZsh{}      \PYZdq{}1stFlrSF\PYZdq{},}
          \PY{c+c1}{\PYZsh{} \PYZsh{}      \PYZdq{}FullBath\PYZdq{},}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}Fireplaces\PYZdq{},}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}GarageYrBlt\PYZdq{},\PYZsh{}nan}
          \PY{c+c1}{\PYZsh{} \PYZsh{}      \PYZdq{}GarageCars\PYZdq{},}
          \PY{c+c1}{\PYZsh{}      \PYZdq{}GarageArea\PYZdq{}}
          \PY{c+c1}{\PYZsh{} ]}
          
          
          \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          \PY{k}{def} \PY{n+nf}{normalize\PYZus{}linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Returns a version of the input `DataFrame` that has all its features normalized linearly.\PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{c+c1}{\PYZsh{}}
            \PY{c+c1}{\PYZsh{} Your code here: normalize the inputs.}
            \PY{c+c1}{\PYZsh{}}
            \PY{n}{new} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{)}
            \PY{n}{new}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{OverallQual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{OverallQual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{new}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GrLivArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GrLivArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}TotRmsAbvGrd\PYZdq{}] = linear\PYZus{}scale(examples\PYZus{}dataframe[\PYZdq{}TotRmsAbvGrd\PYZdq{}])}
            \PY{n}{new}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotalBsmtSF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotalBsmtSF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}1stFlrSF\PYZdq{}] = linear\PYZus{}scale(examples\PYZus{}dataframe[\PYZdq{}1stFlrSF\PYZdq{}])}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}FullBath\PYZdq{}] = linear\PYZus{}scale(examples\PYZus{}dataframe[\PYZdq{}FullBath\PYZdq{}])}
            \PY{n}{new}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fireplaces}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fireplaces}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}GarageYrBlt\PYZdq{}] = linear\PYZus{}scale(examples\PYZus{}dataframe[\PYZdq{}GarageYrBlt\PYZdq{}])}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}GarageCars\PYZdq{}] = linear\PYZus{}scale(examples\PYZus{}dataframe[\PYZdq{}GarageCars\PYZdq{}])}
            \PY{n}{new}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{linear\PYZus{}scale}\PY{p}{(}\PY{n}{examples\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}   new[\PYZdq{}SalePrice\PYZdq{}] = examples\PYZus{}dataframe[\PYZdq{}SalePrice\PYZdq{}]}
            
            \PY{k}{return} \PY{n}{new}
          
          \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          \PY{n}{clipped\PYZus{}feature} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotRmsAbvGrd}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{min}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{13}\PY{p}{)}\PY{p}{)}
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TotRmsAbvGrd}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{clipped\PYZus{}feature}
          
          \PY{n}{clipped\PYZus{}feature} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{OverallQual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{min}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mf}{9.5}\PY{p}{)}\PY{p}{)}
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{OverallQual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{clipped\PYZus{}feature}
          
          \PY{n}{clipped\PYZus{}feature} \PY{o}{=} \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GrLivArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{min}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{3500}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{}was max}
          \PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GrLivArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{clipped\PYZus{}feature}
          \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          
          \PY{n}{normalized\PYZus{}dataframe} \PY{o}{=} \PY{n}{normalize\PYZus{}linear\PYZus{}scale}\PY{p}{(}\PY{n}{preprocess\PYZus{}features}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}dataframe}\PY{p}{)}\PY{p}{)}
          \PY{n}{normalized\PYZus{}training\PYZus{}examples} \PY{o}{=} \PY{n}{normalized\PYZus{}dataframe}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}
          \PY{n}{normalized\PYZus{}validation\PYZus{}examples} \PY{o}{=} \PY{n}{normalized\PYZus{}dataframe}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{460}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          
          
          \PY{c+c1}{\PYZsh{} \PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}TotRmsAbvGrd\PYZdq{}].apply(lambda x: min(x, 13))}
          \PY{c+c1}{\PYZsh{} \PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}TotRmsAbvGrd\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} \PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}OverallQual\PYZdq{}].apply(lambda x: min(x, 9.5))}
          \PY{c+c1}{\PYZsh{} \PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}OverallQual\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} \PYZsh{} clipped\PYZus{}feature = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}GrLivArea\PYZdq{}].apply(lambda x: max(x, 3500))}
          \PY{c+c1}{\PYZsh{} \PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}GrLivArea\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} minimal\PYZus{}training\PYZus{}examples = training\PYZus{}examples[minimal\PYZus{}features]}
          \PY{c+c1}{\PYZsh{} \PYZsh{} clipped\PYZus{}feature = minimal\PYZus{}training\PYZus{}examples[\PYZdq{}TotRmsAbvGrd\PYZdq{}].apply(lambda x: min(x, 13))}
          \PY{c+c1}{\PYZsh{} \PYZsh{} minimal\PYZus{}training\PYZus{}examples[\PYZdq{}TotRmsAbvGrd\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} clipped\PYZus{}feature = training\PYZus{}examples[\PYZdq{}OverallQual\PYZdq{}].apply(lambda x: min(x, 9.5))}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}OverallQual\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} clipped\PYZus{}feature = training\PYZus{}examples[\PYZdq{}GarageArea\PYZdq{}].apply(lambda x: min(x, 1000))}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}GarageArea\PYZdq{}] = clipped\PYZus{}feature}
          
          \PY{c+c1}{\PYZsh{} \PYZsh{} clipped\PYZus{}feature = minimal\PYZus{}training\PYZus{}examples[\PYZdq{}GrLivArea\PYZdq{}].apply(lambda x: max(x, 3500))}
          \PY{c+c1}{\PYZsh{} \PYZsh{} minimal\PYZus{}training\PYZus{}examples[\PYZdq{}GrLivArea\PYZdq{}] = clipped\PYZus{}feature}
          
          
          \PY{n}{minimal\PYZus{}validation\PYZus{}examples} \PY{o}{=} \PY{n}{validation\PYZus{}examples}\PY{p}{[}\PY{n}{minimal\PYZus{}features}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}138}]:} \PY{c+c1}{\PYZsh{} nn\PYZus{}regressor = train\PYZus{}nn\PYZus{}regression\PYZus{}model(}
          \PY{c+c1}{\PYZsh{}     my\PYZus{}optimizer=tf.train.AdamOptimizer(learning\PYZus{}rate=0.005),}
          \PY{c+c1}{\PYZsh{}     steps=2000,}
          \PY{c+c1}{\PYZsh{}     batch\PYZus{}size=40,}
          \PY{c+c1}{\PYZsh{}     hidden\PYZus{}units=[10, 4],}
          \PY{c+c1}{\PYZsh{}     training\PYZus{}examples=minimal\PYZus{}training\PYZus{}examples,\PYZsh{}normalized\PYZus{}training\PYZus{}examples,\PYZsh{}minimal\PYZus{}training\PYZus{}examples,}
          \PY{c+c1}{\PYZsh{}     training\PYZus{}targets=training\PYZus{}targets,}
          \PY{c+c1}{\PYZsh{}     validation\PYZus{}examples=minimal\PYZus{}validation\PYZus{}examples,\PYZsh{}normalized\PYZus{}validation\PYZus{}examples,\PYZsh{}}
          \PY{c+c1}{\PYZsh{}     validation\PYZus{}targets=validation\PYZus{}targets}
          \PY{c+c1}{\PYZsh{} )}
          
          \PY{c+c1}{\PYZsh{} With normalized values it is under 33, but is overfitting}
          \PY{n}{nn\PYZus{}regressor} \PY{o}{=} \PY{n}{train\PYZus{}nn\PYZus{}regression\PYZus{}model}\PY{p}{(}
              \PY{n}{my\PYZus{}optimizer}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.005}\PY{p}{)}\PY{p}{,}
              \PY{n}{steps}\PY{o}{=}\PY{l+m+mi}{5000}\PY{p}{,}
              \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}
              \PY{n}{hidden\PYZus{}units}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{]}\PY{p}{,}
              \PY{n}{training\PYZus{}examples}\PY{o}{=}\PY{n}{normalized\PYZus{}training\PYZus{}examples}\PY{p}{,}\PY{c+c1}{\PYZsh{}minimal\PYZus{}training\PYZus{}examples,\PYZsh{}minimal\PYZus{}training\PYZus{}examples,}
              \PY{n}{training\PYZus{}targets}\PY{o}{=}\PY{n}{training\PYZus{}targets}\PY{p}{,}
              \PY{n}{validation\PYZus{}examples}\PY{o}{=}\PY{n}{normalized\PYZus{}validation\PYZus{}examples}\PY{p}{,}\PY{c+c1}{\PYZsh{}minimal\PYZus{}validation\PYZus{}examples,}
              \PY{n}{validation\PYZus{}targets}\PY{o}{=}\PY{n}{validation\PYZus{}targets}\PY{c+c1}{\PYZsh{}validation\PYZus{}targets}
          \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Training model{\ldots}
RMSE (on training data):
  period 00 : 36.67
  period 01 : 34.82
  period 02 : 35.42
  period 03 : 35.05
  period 04 : 35.01
  period 05 : 34.92
  period 06 : 34.93
  period 07 : 34.71
  period 08 : 34.63
  period 09 : 35.20
Model training finished.
Final RMSE (on training data):   35.20
Final RMSE (on validation data): 36.53

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}122}]:} \PY{c+c1}{\PYZsh{} plt.scatter(training\PYZus{}examples[\PYZdq{}OverallQual\PYZdq{}], training\PYZus{}targets[\PYZdq{}SalePrice\PYZdq{}])}
          \PY{c+c1}{\PYZsh{} plt.scatter(training\PYZus{}examples[\PYZdq{}OverallQual\PYZdq{}], training\PYZus{}targets[\PYZdq{}SalePrice\PYZdq{}])}
          \PY{c+c1}{\PYZsh{} plt.scatter(training\PYZus{}examples[\PYZdq{}GrLivArea\PYZdq{}], training\PYZus{}targets[\PYZdq{}SalePrice\PYZdq{}])}
          \PY{c+c1}{\PYZsh{} plt.scatter(training\PYZus{}examples[\PYZdq{}TotalBsmtSF\PYZdq{}], training\PYZus{}targets[\PYZdq{}SalePrice\PYZdq{}])}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{training\PYZus{}examples}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GarageArea}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{training\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} plt.scatter(training\PYZus{}examples[\PYZdq{}GarageYrBlt\PYZdq{}], training\PYZus{}targets[\PYZdq{}SalePrice\PYZdq{}])}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}OverallQual\PYZdq{}].hist()}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}GrLivArea\PYZdq{}].hist()}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}TotalBsmtSF\PYZdq{}].hist()}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}GarageArea\PYZdq{}].hist()}
          \PY{c+c1}{\PYZsh{} training\PYZus{}examples[\PYZdq{}GarageYrBlt\PYZdq{}]\PYZsh{}.hist()}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}122}]:} <matplotlib.collections.PathCollection at 0x1239b20b8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{california\PYZus{}housing\PYZus{}test\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data/test.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{,}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{california\PYZus{}housing\PYZus{}saleprice\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data/sample\PYZus{}submission.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{,}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}}
         \PY{c+c1}{\PYZsh{} YOUR CODE HERE}
         \PY{c+c1}{\PYZsh{}}
         
         \PY{n}{new\PYZus{}examples} \PY{o}{=} \PY{n}{preprocess\PYZus{}features}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}test\PYZus{}data}\PY{p}{)}
         \PY{n}{new\PYZus{}targets} \PY{o}{=} \PY{n}{preprocess\PYZus{}targets}\PY{p}{(}\PY{n}{california\PYZus{}housing\PYZus{}saleprice\PYZus{}data}\PY{p}{)}
         
         \PY{n}{predict\PYZus{}new\PYZus{}input\PYZus{}fn} \PY{o}{=} \PY{k}{lambda}\PY{p}{:} \PY{n}{my\PYZus{}input\PYZus{}fn}\PY{p}{(}\PY{n}{new\PYZus{}examples}\PY{p}{,} \PY{n}{new\PYZus{}targets}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SalePrice}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
         
         \PY{n}{new\PYZus{}predictions} \PY{o}{=} \PY{n}{nn\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}fn}\PY{o}{=}\PY{n}{predict\PYZus{}new\PYZus{}input\PYZus{}fn}\PY{p}{)}
         \PY{n}{new\PYZus{}predictions} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{item}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{new\PYZus{}predictions}\PY{p}{]}\PY{p}{)}
         
         \PY{n}{new\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{new\PYZus{}predictions}\PY{p}{,} \PY{n}{new\PYZus{}targets}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Final RMSE (on test data): }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{new\PYZus{}root\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        AttributeError                            Traceback (most recent call last)

        <ipython-input-38-fc5b11f35554> in <module>()
         10 predict\_new\_input\_fn = lambda: my\_input\_fn(new\_examples, new\_targets["SalePrice"], num\_epochs=1, shuffle=False)
         11 
    ---> 12 new\_predictions = nn\_regressor.predict(input\_fn=predict\_new\_input\_fn)
         13 new\_predictions = np.array([item['predictions'][0] for item in new\_predictions])
         14 


        AttributeError: 'tuple' object has no attribute 'predict'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{c+c1}{\PYZsh{} \PYZsh{} california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}rooms\PYZus{}per\PYZus{}person\PYZdq{}] = california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}total\PYZus{}rooms\PYZdq{}] / california\PYZus{}housing\PYZus{}dataframe[\PYZdq{}population\PYZdq{}]}
         
         \PY{c+c1}{\PYZsh{} calibration\PYZus{}data = train\PYZus{}model(}
         \PY{c+c1}{\PYZsh{}     learning\PYZus{}rate=.5,}
         \PY{c+c1}{\PYZsh{}     steps=500,}
         \PY{c+c1}{\PYZsh{}     batch\PYZus{}size=5,}
         \PY{c+c1}{\PYZsh{}     input\PYZus{}feature=\PYZdq{}OverallQual\PYZdq{}}
         \PY{c+c1}{\PYZsh{} )}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} def train\PYZus{}model(learning\PYZus{}rate, steps, batch\PYZus{}size, input\PYZus{}feature):}
        \PY{c+c1}{\PYZsh{}   \PYZdq{}\PYZdq{}\PYZdq{}Trains a linear regression model.}
          
        \PY{c+c1}{\PYZsh{}   Args:}
        \PY{c+c1}{\PYZsh{}     learning\PYZus{}rate: A `float`, the learning rate.}
        \PY{c+c1}{\PYZsh{}     steps: A non\PYZhy{}zero `int`, the total number of training steps. A training step}
        \PY{c+c1}{\PYZsh{}       consists of a forward and backward pass using a single batch.}
        \PY{c+c1}{\PYZsh{}     batch\PYZus{}size: A non\PYZhy{}zero `int`, the batch size.}
        \PY{c+c1}{\PYZsh{}     input\PYZus{}feature: A `string` specifying a column from `california\PYZus{}housing\PYZus{}dataframe`}
        \PY{c+c1}{\PYZsh{}       to use as input feature.}
              
        \PY{c+c1}{\PYZsh{}   Returns:}
        \PY{c+c1}{\PYZsh{}     A Pandas `DataFrame` containing targets and the corresponding predictions done}
        \PY{c+c1}{\PYZsh{}     after training the model.}
        \PY{c+c1}{\PYZsh{}   \PYZdq{}\PYZdq{}\PYZdq{}}
          
        \PY{c+c1}{\PYZsh{}   periods = 10}
        \PY{c+c1}{\PYZsh{}   steps\PYZus{}per\PYZus{}period = steps // periods}
        
        \PY{c+c1}{\PYZsh{}   my\PYZus{}feature = input\PYZus{}feature}
        \PY{c+c1}{\PYZsh{}   my\PYZus{}feature\PYZus{}data = california\PYZus{}housing\PYZus{}dataframe[[my\PYZus{}feature]].astype(\PYZsq{}float32\PYZsq{})}
        \PY{c+c1}{\PYZsh{}   my\PYZus{}label = \PYZdq{}SalePrice\PYZdq{}}
        \PY{c+c1}{\PYZsh{}   targets = california\PYZus{}housing\PYZus{}dataframe[my\PYZus{}label].astype(\PYZsq{}float32\PYZsq{})}
        
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Create input functions.}
        \PY{c+c1}{\PYZsh{}   training\PYZus{}input\PYZus{}fn = lambda: my\PYZus{}input\PYZus{}fn(my\PYZus{}feature\PYZus{}data, targets, batch\PYZus{}size=batch\PYZus{}size)}
        \PY{c+c1}{\PYZsh{}   predict\PYZus{}training\PYZus{}input\PYZus{}fn = lambda: my\PYZus{}input\PYZus{}fn(my\PYZus{}feature\PYZus{}data, targets, num\PYZus{}epochs=1, shuffle=False)}
          
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Create feature columns.}
        \PY{c+c1}{\PYZsh{}   feature\PYZus{}columns = [tf.feature\PYZus{}column.numeric\PYZus{}column(my\PYZus{}feature)]}
            
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Create a linear regressor object.}
        \PY{c+c1}{\PYZsh{}   my\PYZus{}optimizer = tf.train.GradientDescentOptimizer(learning\PYZus{}rate=learning\PYZus{}rate)}
        \PY{c+c1}{\PYZsh{}   my\PYZus{}optimizer = tf.contrib.estimator.clip\PYZus{}gradients\PYZus{}by\PYZus{}norm(my\PYZus{}optimizer, 5.0)}
        \PY{c+c1}{\PYZsh{}   linear\PYZus{}regressor = tf.estimator.LinearRegressor(}
        \PY{c+c1}{\PYZsh{}       feature\PYZus{}columns=feature\PYZus{}columns,}
        \PY{c+c1}{\PYZsh{}       optimizer=my\PYZus{}optimizer}
        \PY{c+c1}{\PYZsh{}   )}
        
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Set up to plot the state of our model\PYZsq{}s line each period.}
        \PY{c+c1}{\PYZsh{}   plt.figure(figsize=(15, 6))}
        \PY{c+c1}{\PYZsh{}   plt.subplot(1, 2, 1)}
        \PY{c+c1}{\PYZsh{}   plt.title(\PYZdq{}Learned Line by Period\PYZdq{})}
        \PY{c+c1}{\PYZsh{}   plt.ylabel(my\PYZus{}label)}
        \PY{c+c1}{\PYZsh{}   plt.xlabel(my\PYZus{}feature)}
        \PY{c+c1}{\PYZsh{}   sample = california\PYZus{}housing\PYZus{}dataframe.sample(n=300)}
        \PY{c+c1}{\PYZsh{}   plt.scatter(sample[my\PYZus{}feature], sample[my\PYZus{}label])}
        \PY{c+c1}{\PYZsh{}   colors = [cm.coolwarm(x) for x in np.linspace(\PYZhy{}1, 1, periods)]}
        
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Train the model, but do so inside a loop so that we can periodically assess}
        \PY{c+c1}{\PYZsh{}   \PYZsh{} loss metrics.}
        \PY{c+c1}{\PYZsh{}   print(\PYZdq{}Training model...\PYZdq{})}
        \PY{c+c1}{\PYZsh{}   print(\PYZdq{}RMSE (on training data):\PYZdq{})}
        \PY{c+c1}{\PYZsh{}   root\PYZus{}mean\PYZus{}squared\PYZus{}errors = []}
        \PY{c+c1}{\PYZsh{}   for period in range (0, periods):}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Train the model, starting from the prior state.}
        \PY{c+c1}{\PYZsh{}     linear\PYZus{}regressor.train(}
        \PY{c+c1}{\PYZsh{}         input\PYZus{}fn=training\PYZus{}input\PYZus{}fn,}
        \PY{c+c1}{\PYZsh{}         steps=steps\PYZus{}per\PYZus{}period,}
        \PY{c+c1}{\PYZsh{}     )}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Take a break and compute predictions.}
        \PY{c+c1}{\PYZsh{}     predictions = linear\PYZus{}regressor.predict(input\PYZus{}fn=predict\PYZus{}training\PYZus{}input\PYZus{}fn)}
        \PY{c+c1}{\PYZsh{}     predictions = np.array([item[\PYZsq{}predictions\PYZsq{}][0] for item in predictions])}
            
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Compute loss.}
        \PY{c+c1}{\PYZsh{}     root\PYZus{}mean\PYZus{}squared\PYZus{}error = math.sqrt(}
        \PY{c+c1}{\PYZsh{}       metrics.mean\PYZus{}squared\PYZus{}error(predictions, targets))}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Occasionally print the current loss.}
        \PY{c+c1}{\PYZsh{}     print(\PYZdq{}  period \PYZpc{}02d : \PYZpc{}0.2f\PYZdq{} \PYZpc{} (period, root\PYZus{}mean\PYZus{}squared\PYZus{}error))}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Add the loss metrics from this period to our list.}
        \PY{c+c1}{\PYZsh{}     root\PYZus{}mean\PYZus{}squared\PYZus{}errors.append(root\PYZus{}mean\PYZus{}squared\PYZus{}error)}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Finally, track the weights and biases over time.}
        \PY{c+c1}{\PYZsh{}     \PYZsh{} Apply some math to ensure that the data and line are plotted neatly.}
        \PY{c+c1}{\PYZsh{}     y\PYZus{}extents = np.array([0, sample[my\PYZus{}label].max()])}
            
        \PY{c+c1}{\PYZsh{}     weight = linear\PYZus{}regressor.get\PYZus{}variable\PYZus{}value(\PYZsq{}linear/linear\PYZus{}model/\PYZpc{}s/weights\PYZsq{} \PYZpc{} input\PYZus{}feature)[0]}
        \PY{c+c1}{\PYZsh{}     bias = linear\PYZus{}regressor.get\PYZus{}variable\PYZus{}value(\PYZsq{}linear/linear\PYZus{}model/bias\PYZus{}weights\PYZsq{})}
            
        \PY{c+c1}{\PYZsh{}     x\PYZus{}extents = (y\PYZus{}extents \PYZhy{} bias) // weight}
        \PY{c+c1}{\PYZsh{}     x\PYZus{}extents = np.maximum(np.minimum(x\PYZus{}extents,}
        \PY{c+c1}{\PYZsh{}                                       sample[my\PYZus{}feature].max()),}
        \PY{c+c1}{\PYZsh{}                            sample[my\PYZus{}feature].min())}
        \PY{c+c1}{\PYZsh{}     y\PYZus{}extents = weight * x\PYZus{}extents + bias}
        \PY{c+c1}{\PYZsh{}     plt.plot(x\PYZus{}extents, y\PYZus{}extents, color=colors[period]) }
        \PY{c+c1}{\PYZsh{}   print(\PYZdq{}Model training finished.\PYZdq{})}
        
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Output a graph of loss metrics over periods.}
        \PY{c+c1}{\PYZsh{}   plt.subplot(1, 2, 2)}
        \PY{c+c1}{\PYZsh{}   plt.ylabel(\PYZsq{}RMSE\PYZsq{})}
        \PY{c+c1}{\PYZsh{}   plt.xlabel(\PYZsq{}Periods\PYZsq{})}
        \PY{c+c1}{\PYZsh{}   plt.title(\PYZdq{}Root Mean Squared Error vs. Periods\PYZdq{})}
        \PY{c+c1}{\PYZsh{}   plt.tight\PYZus{}layout()}
        \PY{c+c1}{\PYZsh{}   plt.plot(root\PYZus{}mean\PYZus{}squared\PYZus{}errors)}
        
        \PY{c+c1}{\PYZsh{}   \PYZsh{} Create a table with calibration data.}
        \PY{c+c1}{\PYZsh{}   calibration\PYZus{}data = pd.DataFrame()}
        \PY{c+c1}{\PYZsh{}   calibration\PYZus{}data[\PYZdq{}predictions\PYZdq{}] = pd.Series(predictions)}
        \PY{c+c1}{\PYZsh{}   calibration\PYZus{}data[\PYZdq{}targets\PYZdq{}] = pd.Series(targets)}
        \PY{c+c1}{\PYZsh{}   display.display(calibration\PYZus{}data.describe())}
        
        \PY{c+c1}{\PYZsh{}   print(\PYZdq{}Final RMSE (on training data): \PYZpc{}0.2f\PYZdq{} \PYZpc{} root\PYZus{}mean\PYZus{}squared\PYZus{}error)}
          
        \PY{c+c1}{\PYZsh{}   return calibration\PYZus{}data}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
